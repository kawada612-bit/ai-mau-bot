
import time
import json
import sys
from datetime import datetime, timedelta, timezone
from dateutil.relativedelta import relativedelta
from playwright.sync_api import sync_playwright
from supabase import create_client
from groq import Groq
from src.core import config
from src.core.logger import setup_logger

logger = setup_logger(__name__)

# å®šæ•°
TIMETREE_BASE_URL: str = "https://timetreeapp.com/public_calendars/lollipop_1116"

# GroqåˆæœŸåŒ–
groq_client: Groq | None = None
if config.GROQ_API_KEY:
    groq_client = Groq(api_key=config.GROQ_API_KEY)

def check_env_vars() -> bool:
    """ç’°å¢ƒå¤‰æ•°ã®è¨­å®šçŠ¶æ³ã‚’ç¢ºèª"""
    logger.info("--- âš™ï¸ è¨­å®šãƒã‚§ãƒƒã‚¯ ---")
    logger.info(f"Supabase URL : {'âœ… OK' if config.SUPABASE_URL else 'âŒ Missing'}")
    logger.info(f"Supabase Key : {'âœ… OK' if config.SUPABASE_KEY else 'âŒ Missing'}")
    logger.info(f"Groq Key     : {'âœ… OK' if config.GROQ_API_KEY else 'âŒ Missing'}")
    logger.info("-----------------------")
    return bool(config.SUPABASE_URL and config.SUPABASE_KEY)

def refine_time_with_groq(title: str, date_str: str, note: str) -> tuple[str | None, str | None]:
    """Groq (Llama 3) ã§ãƒ¡ãƒ¢æ¬„ã‹ã‚‰æ™‚é–“ã‚’æŠ½å‡º"""
    if not note or not groq_client: return None, None
    
    prompt = f"""
    You are a scheduler assistant. Extract START and END times from the text.
    
    [Input]
    Date: {date_str}
    Title: {title}
    Note: {note}

    [Rules]
    1. Output JSON: {{ "start_at": "YYYY-MM-DDTHH:MM:SS+09:00", "end_at": "..." or null }}
    2. Handle "1040" as "10:40".
    3. If "OPEN" and "START" exist, use "START". If only "OPEN", use "OPEN".
    4. If time is "TBA" or unknown, return null for both.
    """
    
    try:
        completion = groq_client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "system", "content": "Output JSON only."},
                {"role": "user", "content": prompt}
            ],
            temperature=0,
            response_format={"type": "json_object"}
        )
        content = completion.choices[0].message.content or "{}"
        data = json.loads(content)
        return data.get("start_at"), data.get("end_at")
    except Exception as e:
        logger.warning(f"AIè§£æã‚¨ãƒ©ãƒ¼: {e}")
        return None, None

def fetch_and_sync() -> None:
    if not check_env_vars(): return
    
    logger.info("ğŸš€ åŒæœŸãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ã—ã¾ã™ (å¼·åˆ¶å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰)...")
    all_events = {}

    with sync_playwright() as p:
        logger.info("ğŸŒ ãƒ–ãƒ©ã‚¦ã‚¶èµ·å‹•ä¸­...")
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()

        def handle_response(response):
            if "public_events" in response.url and response.status == 200:
                try:
                    data = response.json()
                    events = data.get("public_events", [])
                    for e in events:
                        all_events[e["id"]] = e
                except: pass

        page.on("response", handle_response)

        # ä»Šæœˆã‹ã‚‰å‘ã“ã†4ãƒ¶æœˆåˆ†ã‚’ã‚·ãƒ³ãƒ—ãƒ«ã«å·¡å›
        today = datetime.now()
        for i in range(4):
            target_date = today + relativedelta(months=i)
            date_param = target_date.strftime("%Y-%m-01")
            url = f"{TIMETREE_BASE_URL}?monthly={date_param}"
            
            logger.info(f"ğŸ”„ å·¡å›: {date_param} ...")
            try:
                page.goto(url, wait_until="networkidle")
                page.wait_for_timeout(1500)
            except Exception as e:
                logger.warning(f"âš ï¸ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {e}")

        browser.close()

    if not all_events:
        logger.warning("âŒ ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    # ãƒ‡ãƒ¼ã‚¿æ•´å½¢ã¨ä¿å­˜
    upsert_data = []
    events_list = list(all_events.values())
    logger.info(f"ğŸ“¦ åˆè¨ˆ {len(events_list)} ä»¶ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‡¦ç†ä¸­...")

    for event in events_list:
        try:
            source_id = str(event["id"])
            title = event.get("title", "")
            note = event.get("note", "")
            raw_start = event["start_at"] / 1000
            
            # æ›´æ–°æ—¥æ™‚ã®å–å¾—
            raw_updated_at = event.get("updated_at")
            if raw_updated_at:
                updated_at_dt = datetime.fromtimestamp(raw_updated_at / 1000, timezone.utc)
            else:
                updated_at_dt = datetime.now(timezone.utc)

            dt_obj = datetime.fromtimestamp(raw_start, timezone(timedelta(hours=9)))
            start_at = dt_obj.isoformat()
            end_at = None
            is_all_day = event.get("all_day", False)

            # AIè£œæ­£
            if note and groq_client:
                # Same-line progress logging not ideal with standard logging, changing to minimal log
                # logger currently adds newlines.
                # Just log finding
                ai_start, ai_end = refine_time_with_groq(title, dt_obj.strftime('%Y-%m-%d'), note)
                
                if ai_start:
                    start_at = ai_start
                    is_all_day = False
                    if ai_end: end_at = ai_end
                    logger.info(f"  ğŸ¤– AIè§£ææˆåŠŸ: {title[:15]}... -> {ai_start}")
                    time.sleep(0.3)
                else:
                    logger.debug(f"  ğŸ¤– AIè§£æã‚¹ã‚­ãƒƒãƒ—: {title[:15]}...")

            upsert_data.append({
                "source_id": source_id,
                "title": title,
                "start_at": start_at,
                "end_at": end_at,
                "description": note,
                "url": event.get("url", ""),
                "image_url": None,
                "is_all_day": is_all_day,
                "updated_at": updated_at_dt.isoformat()
            })
        except Exception as e:
            logger.error(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")

    if upsert_data:
        try:
            if config.SUPABASE_URL and config.SUPABASE_KEY:
                supabase = create_client(config.SUPABASE_URL, config.SUPABASE_KEY)
                supabase.table("schedules").upsert(upsert_data, on_conflict="source_id").execute()
                logger.info(f"âœ… åŒæœŸå®Œäº†ï¼ {len(upsert_data)} ä»¶ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
            else:
                logger.error("Supabase config failed")
        except Exception as e:
            logger.error(f"âŒ DBä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    else:
        logger.warning("âš ï¸ ä¿å­˜ãƒ‡ãƒ¼ã‚¿ãªã—")

if __name__ == "__main__":
    fetch_and_sync()
